{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique PMCIDs:  17357\n",
      "Number of sentences:  993984\n",
      "Counter({'NO_AGR': 555589, 'NONE': 400055, '12a': 25821, '4a': 4715, '7a': 3139, '6a': 1854, '3a': 1451, '5': 657, '11a': 300, '10': 129, '8b': 127, '4b': 112, '7b': 28, '9': 3, '12b': 3, '8a': 1})\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "#preprocess all_agree_filtered data\n",
    "all_agreed_data_file = \"/efs/lhoang2/all_agree_filtered.txt\"\n",
    "df = pd.read_csv(all_agreed_data_file, sep = \"|\",header = None)\n",
    "df.columns = [\"PMCID\",\"sentence_id\",\"CONSORT_Item\",\"sentence\"]\n",
    "df.head(10)\n",
    "\n",
    "PMCID_list = df[\"PMCID\"]\n",
    "unique_PMCID_list = list(set(PMCID_list))\n",
    "print (\"Number of unique PMCIDs: \", len(unique_PMCID_list))\n",
    "\n",
    "sentence_id_list = df[\"sentence_id\"]\n",
    "print (\"Number of sentences: \", len(sentence_id_list))\n",
    "\n",
    "labels = df[\"CONSORT_Item\"]\n",
    "labels = labels.tolist()\n",
    "value_counts = Counter(labels)\n",
    "print (value_counts)\n",
    "\n",
    "\n",
    "#drop CONSORT items NO_AGR, 8a, 12b, 9\n",
    "array = ['NO_AGR', '8a', '12b', '9']\n",
    "filtered_df = df.loc[~df['CONSORT_Item'].isin(array)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PREPROCESSING AUTOMATIC ANNOTATED DATA ####\n",
    "\n",
    "from xml.etree import ElementTree as ET\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def read_xml_section(filePath):\n",
    "    PMCID = filePath.replace(\".xml\",\"\")\n",
    "    PMCID = PMCID.replace(\"/efs/CONSORT/PMC_Internal/\",\"\")\n",
    "    tree = ET.parse(filePath)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    document_id_list = []\n",
    "    section_title_list = []\n",
    "    section_start_list = []\n",
    "    section_end_list = []\n",
    "    section_sub_or_not_list = []\n",
    "    \n",
    "    for child in root:\n",
    "        if child.tag == \"section\":\n",
    "            if len(child) == 0:\n",
    "                sectionTextSpan = child.attrib[\"textSpan\"]                \n",
    "                if 'title' in child.attrib:\n",
    "                    sectionTitle = child.attrib[\"title\"]\n",
    "                else:\n",
    "                    sectionTitle = \"None\"\n",
    "                \n",
    "                sectionSubSectionOrNot = \"No\"\n",
    "                startSectionChar, endSectionchar = sectionTextSpan.split(\"-\")\n",
    "                     \n",
    "                document_id_list.append(PMCID)\n",
    "                section_title_list.append(sectionTitle)\n",
    "                section_start_list.append(startSectionChar)\n",
    "                section_end_list.append(endSectionchar)\n",
    "                section_sub_or_not_list.append(sectionSubSectionOrNot)\n",
    "                    \n",
    "            if len(child) != 0:\n",
    "                sectionTextSpan = child.attrib[\"textSpan\"]\n",
    "                if 'title' in child.attrib:\n",
    "                    sectionTitle = child.attrib[\"title\"]\n",
    "                else:\n",
    "                    sectionTitle = \"None\"\n",
    "                startSectionChar, endSectionchar = sectionTextSpan.split(\"-\")\n",
    "                sectionSubSectionOrNot = \"No\"\n",
    "                \n",
    "                document_id_list.append(PMCID)\n",
    "                section_title_list.append(sectionTitle)\n",
    "                section_start_list.append(startSectionChar)\n",
    "                section_end_list.append(endSectionchar)\n",
    "                section_sub_or_not_list.append(sectionSubSectionOrNot)\n",
    "                \n",
    "                \n",
    "                for child_level1 in child:\n",
    "                    subSectionTextSpan = child_level1.attrib[\"textSpan\"]\n",
    "                    if 'title' in child_level1.attrib:\n",
    "                        subSectionTitle = child_level1.attrib[\"title\"]\n",
    "                    else:\n",
    "                        subSectionTitle = \"None\"\n",
    "                    startSubSectionChar, endSubSectionchar = subSectionTextSpan.split(\"-\")\n",
    "                    sectionSubSectionOrNot = \"Yes\"\n",
    "                                        \n",
    "                    document_id_list.append(PMCID)\n",
    "                    section_title_list.append(subSectionTitle)\n",
    "                    section_start_list.append(startSubSectionChar)\n",
    "                    section_end_list.append(endSubSectionchar)\n",
    "                    section_sub_or_not_list.append(sectionSubSectionOrNot)\n",
    "    \n",
    "    section_df = pd.DataFrame(\n",
    "    {'PMCID': document_id_list,\n",
    "     'section_title': section_title_list,\n",
    "     'section_start': section_start_list,\n",
    "     'section_end': section_end_list,\n",
    "     'subsection?': section_sub_or_not_list\n",
    "    })\n",
    "    return section_df\n",
    "\n",
    "                    \n",
    "def read_xml(filePath):\n",
    "    section_df = read_xml_section(filePath)\n",
    "    \n",
    "    PMCID = filePath.replace(\".xml\",\"\")\n",
    "    PMCID = PMCID.replace(\"/efs/CONSORT/PMC_Internal/\",\"\")\n",
    "    tree = ET.parse(filePath)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    document_id_list = []\n",
    "    sentence_list = []\n",
    "    sentence_id_list = []\n",
    "    start_char_list = []\n",
    "    end_char_list = []\n",
    "    section_list = []\n",
    "\n",
    "    for child in root:\n",
    "        if child.tag == \"sentence\":\n",
    "            charOffSet = (child.attrib[\"charOffset\"])\n",
    "            sentence_id= (child.attrib[\"id\"])\n",
    "            start_char,end_char = charOffSet.split(\"-\")\n",
    "            \n",
    "            for index_section,row_section in section_df.iterrows():\n",
    "                if (PMCID == row_section[\"PMCID\"] and int(start_char)>=int(row_section[\"section_start\"]) and int(end_char)<=int(row_section[\"section_end\"])):\n",
    "                    section = row_section[\"section_title\"]\n",
    "            \n",
    "            for child_level1 in child:\n",
    "                if child_level1.tag == \"text\":\n",
    "                    sentence_text = child_level1.text\n",
    "                    \n",
    "                    document_id_list.append(PMCID)\n",
    "                    sentence_id_list.append(sentence_id)\n",
    "                    sentence_list.append(sentence_text)\n",
    "                    start_char_list.append(start_char)\n",
    "                    end_char_list.append(end_char)\n",
    "                    section_list.append(section)\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "    {'PMCID': document_id_list,\n",
    "     'sentence_id': sentence_id_list,\n",
    "     'sentence_text': sentence_list,\n",
    "     'start_char_pos': start_char_list,\n",
    "     'end_char_pos': end_char_list,\n",
    "     'section': section_list\n",
    "    })\n",
    "    return df\n",
    "\n",
    "data_path = \"/efs/CONSORT/PMC_Internal/\"\n",
    "filelist = os.listdir(data_path)\n",
    "\n",
    "columns=['PMCID', 'sentence_id','sentence_text', 'start_char_pos','end_char_pos','section']\n",
    "all_data_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "count = 0\n",
    "for i in filelist:\n",
    "    if i.endswith(\"xml\"):\n",
    "        file_path = data_path + i\n",
    "        print (file_path)\n",
    "        count +=1\n",
    "        print (count)\n",
    "        data_df = read_xml(file_path)\n",
    "        all_data_df = pd.concat([all_data_df,data_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(filtered_df, all_data_df, on=[\"PMCID\",\"sentence_id\"], how=\"right\")\n",
    "merged_df.to_csv(\"/efs/lhoang2/All_Automatic_Annotated_Data_(TrainingSet).csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

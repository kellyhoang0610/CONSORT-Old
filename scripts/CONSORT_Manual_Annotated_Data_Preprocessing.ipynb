{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PREPROCESSING MANUAL ANNOTATED DATA ####\n",
    "### 50 PMC Articles ####\n",
    "\n",
    "from xml.etree import ElementTree as ET\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def read_xml_section(filePath):\n",
    "    PMCID = filePath.replace(\".xml\",\"\")\n",
    "    PMCID = PMCID.replace(\"/Users/phuong/Documents/skr-consort-master/datasets/XML_50/\",\"\")\n",
    "    tree = ET.parse(filePath)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    document_id_list = []\n",
    "    section_title_list = []\n",
    "    section_start_list = []\n",
    "    section_end_list = []\n",
    "    section_sub_or_not_list = []\n",
    "    \n",
    "    for child in root:\n",
    "        if child.tag == \"section\":\n",
    "            if len(child) == 0:\n",
    "                sectionTextSpan = child.attrib[\"textSpan\"]\n",
    "                sectionTitle = child.attrib[\"title\"]\n",
    "                sectionSubSectionOrNot = \"No\"\n",
    "                startSectionChar, endSectionchar = sectionTextSpan.split(\"-\")\n",
    "                     \n",
    "                document_id_list.append(PMCID)\n",
    "                section_title_list.append(sectionTitle)\n",
    "                section_start_list.append(startSectionChar)\n",
    "                section_end_list.append(endSectionchar)\n",
    "                section_sub_or_not_list.append(sectionSubSectionOrNot)\n",
    "                    \n",
    "            if len(child) != 0:\n",
    "                sectionTextSpan = child.attrib[\"textSpan\"]\n",
    "                sectionTitle = child.attrib[\"title\"]\n",
    "                startSectionChar, endSectionchar = sectionTextSpan.split(\"-\")\n",
    "                sectionSubSectionOrNot = \"No\"\n",
    "                \n",
    "                document_id_list.append(PMCID)\n",
    "                section_title_list.append(sectionTitle)\n",
    "                section_start_list.append(startSectionChar)\n",
    "                section_end_list.append(endSectionchar)\n",
    "                section_sub_or_not_list.append(sectionSubSectionOrNot)\n",
    "                \n",
    "                \n",
    "                for child_level1 in child:\n",
    "                    subSectionTextSpan = child_level1.attrib[\"textSpan\"]\n",
    "                    subSectionTitle = child_level1.attrib[\"title\"]\n",
    "                    startSubSectionChar, endSubSectionchar = subSectionTextSpan.split(\"-\")\n",
    "                    sectionSubSectionOrNot = \"Yes\"\n",
    "                                        \n",
    "                    document_id_list.append(PMCID)\n",
    "                    section_title_list.append(subSectionTitle)\n",
    "                    section_start_list.append(startSubSectionChar)\n",
    "                    section_end_list.append(endSubSectionchar)\n",
    "                    section_sub_or_not_list.append(sectionSubSectionOrNot)\n",
    "    \n",
    "    section_df = pd.DataFrame(\n",
    "    {'PMCID': document_id_list,\n",
    "     'section_title': section_title_list,\n",
    "     'section_start': section_start_list,\n",
    "     'section_end': section_end_list,\n",
    "     'subsection?': section_sub_or_not_list\n",
    "    })\n",
    "    return section_df\n",
    "\n",
    "                    \n",
    "def read_xml(filePath):\n",
    "    section_df = read_xml_section(filePath)\n",
    "    \n",
    "    PMCID = filePath.replace(\".xml\",\"\")\n",
    "    PMCID = PMCID.replace(\"/Users/phuong/Documents/skr-consort-master/datasets/XML_50/\",\"\")\n",
    "    tree = ET.parse(filePath)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    document_id_list = []\n",
    "    sentence_list = []\n",
    "    sentence_id_list = []\n",
    "    start_char_list = []\n",
    "    end_char_list = []\n",
    "    section_list = []\n",
    "\n",
    "    for child in root:\n",
    "        if child.tag == \"sentence\":\n",
    "            charOffSet = (child.attrib[\"charOffset\"])\n",
    "            sentence_id= (child.attrib[\"id\"])\n",
    "            start_char,end_char = charOffSet.split(\"-\")\n",
    "            \n",
    "            for index_section,row_section in section_df.iterrows():\n",
    "                if (PMCID == row_section[\"PMCID\"] and int(start_char)>=int(row_section[\"section_start\"]) and int(end_char)<=int(row_section[\"section_end\"])):\n",
    "                    section = row_section[\"section_title\"]\n",
    "            \n",
    "            for child_level1 in child:\n",
    "                if child_level1.tag == \"text\":\n",
    "                    sentence_text = child_level1.text\n",
    "                    \n",
    "                    document_id_list.append(PMCID)\n",
    "                    sentence_id_list.append(sentence_id)\n",
    "                    sentence_list.append(sentence_text)\n",
    "                    start_char_list.append(start_char)\n",
    "                    end_char_list.append(end_char)\n",
    "                    section_list.append(section)\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "    {'PMCID': document_id_list,\n",
    "     'sentence_id': sentence_id_list,\n",
    "     'sentence_text': sentence_list,\n",
    "     'start_char_pos': start_char_list,\n",
    "     'end_char_pos': end_char_list,\n",
    "     'section': section_list\n",
    "    })\n",
    "    return df\n",
    "\n",
    "data_path = \"/Users/phuong/Documents/skr-consort-master/datasets/XML_50/\"\n",
    "filelist = os.listdir(data_path)\n",
    "\n",
    "columns=['PMCID', 'sentence_id','sentence_text', 'start_char_pos','end_char_pos','section']\n",
    "all_data_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "\n",
    "for i in filelist:\n",
    "    if i.endswith(\"xml\"):\n",
    "        file_path = data_path + i    \n",
    "        data_df = read_xml(file_path)\n",
    "        all_data_df = pd.concat([all_data_df,data_df])\n",
    "\n",
    "#import consort_golden_label data file\n",
    "consort_golden_label_data_file = \"/Users/phuong/Documents/skr-consort-master/datasets/gold_50.txt\"\n",
    "consort_golden_label_df = pd.read_csv(consort_golden_label_data_file, header = None, sep = \"|\")\n",
    "consort_golden_label_df.columns = [\"PMCID\",\"sentence_id\",\"CONSORT_Item\"]\n",
    "\n",
    "\n",
    "merged_df = pd.merge(consort_golden_label_df, all_data_df, on=[\"PMCID\",\"sentence_id\"], how=\"right\")\n",
    "merged_df.to_csv(\"/Users/phuong/Documents/skr-consort-master/datasets/All_Manual_Annotated_Data_(Testing).csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10709\n",
      "2460\n",
      "2637\n"
     ]
    }
   ],
   "source": [
    "#EXTRACT FEATURES FROM TEXT\n",
    "import pandas as pd     \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "#Read data\n",
    "data_file = \"/Users/phuong/Documents/skr-consort-master/datasets/All_Manual_Annotated_Data_(Testing).csv\"\n",
    "data_df = pd.read_csv(data_file, encoding = \"latin\")\n",
    "all_sentence_text = data_df[\"sentence_text\"]\n",
    "print (len(all_sentence_text))\n",
    "\n",
    "#Get data that has annotation\n",
    "data_filter_df = data_df[data_df[\"CONSORT_Item\"].notnull()]\n",
    "sentence_text = data_filter_df[\"sentence_text\"]\n",
    "print (len(sentence_text))\n",
    "\n",
    "#preprocess sentence text\n",
    "clean_sentence_list = []\n",
    "for sentence in sentence_text:\n",
    "    clean_sentence = \"\"\n",
    "    words = sentence.split(\" \")\n",
    "    for word in words:\n",
    "        word = re.sub(r'\\W+', ' ', word)\n",
    "        word = word.lstrip()\n",
    "        word = word.rstrip()\n",
    "        if not word in stop_words: \n",
    "            if not re.match(\"[^A-Za-z0-9]+\", word):\n",
    "                word = re.sub(r'[^\\x00-\\x7F]+',' ', word)\n",
    "                clean_sentence = clean_sentence + \" \" + word\n",
    "    clean_sentence_list.append(clean_sentence)\n",
    "\n",
    "data_filter_df[\"clean_sentence_text\"] = clean_sentence_list\n",
    "data_filter_df.head(10)\n",
    "\n",
    "# remove whitespace and split by ','\n",
    "data_filter_df['CONSORT_Item'] = data_filter_df['CONSORT_Item'].str.replace(' ', '').str.split(',')\n",
    "\n",
    "# construct expanded dataframe\n",
    "res = pd.DataFrame({'CONSORT_Item': list(chain.from_iterable(data_filter_df['CONSORT_Item'])),\n",
    "                    'PMCID': np.repeat(data_filter_df['PMCID'], data_filter_df['CONSORT_Item'].map(len)),\n",
    "                    'sentence_id': np.repeat(data_filter_df['sentence_id'], data_filter_df['CONSORT_Item'].map(len)),\n",
    "                    'start_char_pos': np.repeat(data_filter_df['start_char_pos'], data_filter_df['CONSORT_Item'].map(len)),\n",
    "                    'end_char_pos': np.repeat(data_filter_df['end_char_pos'], data_filter_df['CONSORT_Item'].map(len)),\n",
    "                    'section': np.repeat(data_filter_df['section'], data_filter_df['CONSORT_Item'].map(len)),\n",
    "                    'clean_sentence_text': np.repeat(data_filter_df['clean_sentence_text'], data_filter_df['CONSORT_Item'].map(len))})\n",
    "\n",
    "sentence_text = res[\"clean_sentence_text\"]\n",
    "print (len(sentence_text))\n",
    "sentence_text.to_csv(\"/Users/phuong/Documents/skr-consort-master/datasets/sentence_text.txt\",index=False)\n",
    "\n",
    "#drop CONSORT items <3a and >12\n",
    "array = ['13a','13b','14a','15','16','17a','23','24', '25']\n",
    "main_df = res.loc[~res['CONSORT_Item'].isin(array)]\n",
    "main_df.to_csv(\"/Users/phuong/Documents/skr-consort-master/datasets/All_Manual_Annotated_Data_Cleaned_(Testing).csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

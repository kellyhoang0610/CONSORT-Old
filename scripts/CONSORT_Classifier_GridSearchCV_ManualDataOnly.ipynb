{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2002\n",
      "550\n",
      "Manual train labels distribution:  Counter({'6a': 523, '0': 493, '5': 217, '12a': 213, '4a': 123, '7a': 83, '12b': 55, '3a': 52, '10': 46, '11a': 45, '8b': 39, '8a': 33, '4b': 29, '9': 16, '11b': 15, '7b': 10, '3b': 7, '6b': 3})\n",
      "Manual test labels distribution:  Counter({'0': 137, '6a': 132, '12a': 56, '5': 52, '4a': 37, '7a': 30, '12b': 17, '3a': 15, '11a': 12, '10': 11, '4b': 10, '8b': 10, '8a': 10, '9': 6, '7b': 6, '6b': 3, '11b': 3, '3b': 3})\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, cross_val_predict\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix,roc_auc_score, roc_curve, precision_recall_curve\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.fixes import signature\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from scipy.sparse import coo_matrix, hstack, vstack\n",
    "from collections import Counter\n",
    "\n",
    "#Read manual annotated data\n",
    "old_train_data_file = \"/efs/CONSORT/MLDataset/valid_data_withMetamap.csv\"\n",
    "old_test_data_file = \"/efs/CONSORT/MLDataset/test_data_withMetamap.csv\"\n",
    "\n",
    "old_automatic_train_data_file = \"/efs/CONSORT/MLDataset/train_data_withMetamap.csv\"\n",
    "\n",
    "old_train_data_df = pd.read_csv(old_train_data_file, encoding = \"latin\")\n",
    "old_test_data_df = pd.read_csv(old_test_data_file, encoding = \"latin\")\n",
    "old_automatic_train_data_df = pd.read_csv(old_automatic_train_data_file, encoding = \"latin\")\n",
    "\n",
    "old_train_data_df = old_train_data_df[[\"PMCID\", \"sentence_id\",\"CONSORT_Item\",\"section\",\"sentence_text\",\"metamap_concepts\",\"metamap_concepts_text\",\"metamap_semantictypes\"]]\n",
    "old_test_data_df = old_test_data_df[[\"PMCID\", \"sentence_id\",\"CONSORT_Item\",\"section\",\"sentence_text\",\"metamap_concepts\",\"metamap_concepts_text\",\"metamap_semantictypes\"]]\n",
    "old_automatic_train_data_df = old_automatic_train_data_df[[\"PMCID\", \"sentence_id\",\"CONSORT_Item\",\"section\",\"sentence_text\",\"metamap_concepts\",\"metamap_concepts_text\",\"metamap_semantictypes\"]]\n",
    "\n",
    "all_old_data = pd.concat([old_train_data_df,old_test_data_df])\n",
    "\n",
    "#NEW SPLIT FROM HALIL:\n",
    "# new_train_data_file = \"/efs/CONSORT/MLDataset/rare_data.csv\"\n",
    "new_train_data_file = \"/efs/CONSORT/MLDataset/split_train.csv\"\n",
    "new_test_data_file = \"/efs/CONSORT/MLDataset/split_test.csv\"\n",
    "\n",
    "new_train_data_df = pd.read_csv(new_train_data_file, encoding = \"latin\")\n",
    "new_test_data_df = pd.read_csv(new_test_data_file, encoding = \"latin\")\n",
    "\n",
    "new_train_data_df = new_train_data_df[[\"PMCID\", \"sentence_id\",\"text\",\"labels\",\"CONSORT_Item\",\"n_labels\"]]\n",
    "new_test_data_df = new_test_data_df[[\"PMCID\", \"sentence_id\",\"text\",\"labels\",\"CONSORT_Item\",\"n_labels\"]]\n",
    "\n",
    "train_data_df = pd.merge(new_train_data_df,all_old_data, on = [\"PMCID\",\"sentence_id\"], how = \"left\")\n",
    "# train_data_df = pd.merge(new_train_data_df,old_automatic_train_data_df, on = [\"PMCID\",\"sentence_id\"], how = \"left\")\n",
    "print (len(train_data_df))\n",
    "train_data_df = train_data_df[[\"PMCID\", \"sentence_id\",\"CONSORT_Item_y\",\"section\",\"sentence_text\",\"metamap_concepts\",\"metamap_concepts_text\",\"metamap_semantictypes\"]]\n",
    "train_data_df.rename(columns = {'CONSORT_Item_y':'CONSORT_Item'}, inplace = True) \n",
    "\n",
    "test_data_df = pd.merge(new_test_data_df,all_old_data, on = [\"PMCID\",\"sentence_id\"], how = \"left\")\n",
    "# print (len(test_data_df))\n",
    "test_data_df = test_data_df[[\"PMCID\", \"sentence_id\",\"CONSORT_Item_y\",\"section\",\"sentence_text\",\"metamap_concepts\",\"metamap_concepts_text\",\"metamap_semantictypes\"]]\n",
    "test_data_df.rename(columns = {'CONSORT_Item_y':'CONSORT_Item'}, inplace = True) \n",
    "print (len(test_data_df))\n",
    "\n",
    "train_labels = train_data_df[\"CONSORT_Item\"]\n",
    "train_labels = train_labels.tolist()\n",
    "train_value_counts = Counter(train_labels)\n",
    "print (\"Manual train labels distribution: \", train_value_counts)\n",
    "\n",
    "test_labels = test_data_df[\"CONSORT_Item\"]\n",
    "test_labels = test_labels.tolist()\n",
    "test_value_counts = Counter(test_labels)\n",
    "print (\"Manual test labels distribution: \", test_value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:  (2002, 31798)\n",
      "Test data:  (550, 31798)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "# TRAINING DATA\n",
    "#Extract features from training data\n",
    "#Get ngram features\n",
    "vectorizer = CountVectorizer(ngram_range = (2,2))\n",
    "train_text_features = vectorizer.fit_transform(train_data_df['sentence_text'])\n",
    "#select the best k bigram features\n",
    "selector = SelectKBest(chi2, k = 'all').fit(train_text_features, train_data_df['CONSORT_Item'])\n",
    "train_text_features_selected = selector.transform(train_text_features) \n",
    "\n",
    "#Get section header feature\n",
    "lb_make = LabelBinarizer()\n",
    "train_header_features = lb_make.fit_transform(train_data_df[\"section\"].astype(str))\n",
    "train_header_features = np.asmatrix(train_header_features)\n",
    "\n",
    "#Get Metamap features\n",
    "metamap_concepts_unique = []\n",
    "train_metamap_concepts = list(train_data_df['metamap_concepts'])\n",
    "for concepts in train_metamap_concepts:\n",
    "    if pd.notna(concepts) :\n",
    "        concept_items  = concepts.split(\"|\")\n",
    "        for concept_item in concept_items:\n",
    "            if concept_item not in metamap_concepts_unique:\n",
    "                metamap_concepts_unique.append(concept_item)\n",
    "                \n",
    "metamap_semantictypes_unique = []\n",
    "train_metamap_semantictypes = list(train_data_df['metamap_semantictypes'])\n",
    "for semantictypes in train_metamap_semantictypes:\n",
    "    if pd.notna(semantictypes) :\n",
    "        semantictypes_items  = semantictypes.split(\"|\")\n",
    "        for semantictypes_item in semantictypes_items:\n",
    "            if semantictypes_item not in metamap_semantictypes_unique:\n",
    "                metamap_semantictypes_unique.append(semantictypes_item)\n",
    "\n",
    "mlb = MultiLabelBinarizer(classes=metamap_concepts_unique)\n",
    "train_metamap_concepts_features = mlb.fit_transform(train_data_df[\"metamap_concepts\"].astype(str))\n",
    "\n",
    "mlb_semantictype = MultiLabelBinarizer(classes=metamap_semantictypes_unique)\n",
    "train_semantictype_features = mlb_semantictype.fit_transform(train_data_df[\"metamap_semantictypes\"].astype(str))\n",
    "\n",
    "# DEFINE WHICH FEATURES DO YOU WANT TO USE \n",
    "X_train_dm = hstack([train_text_features_selected,train_header_features,train_metamap_concepts_features,train_semantictype_features])\n",
    "# X_train_dm = hstack([train_text_features_selected,train_header_features])\n",
    "# X_train_dm = train_text_features_selected\n",
    "\n",
    "print (\"Training data: \" , X_train_dm.shape)\n",
    "y_train_dm = train_data_df['CONSORT_Item']\n",
    "\n",
    "#TESTING DATA \n",
    "test_text = test_data_df['sentence_text']\n",
    "test_text_features = vectorizer.transform(test_text)\n",
    "test_text_features_selected = selector.transform(test_text_features) \n",
    "test_header_features = lb_make.transform(test_data_df[\"section\"])\n",
    "test_header_features = np.asmatrix(test_header_features)\n",
    "test_metamap_concepts_features = mlb.transform(test_data_df[\"metamap_concepts\"].astype(str))\n",
    "test_semantictype_features = mlb_semantictype.transform(test_data_df[\"metamap_semantictypes\"].astype(str))\n",
    "\n",
    "# DEFINE WHICH FEATURES DO YOU WANT TO USE \n",
    "X_test_dm = hstack([test_text_features_selected,test_header_features,test_metamap_concepts_features,test_semantictype_features])\n",
    "# X_test_dm = hstack([test_text_features_selected,test_header_features])\n",
    "# X_test_dm = test_text_features_selected\n",
    "\n",
    "print (\"Test data: \", X_test_dm.shape)\n",
    "y_test_dm = test_data_df['CONSORT_Item']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
    "import numpy\n",
    "\n",
    "X_train = X_train_dm\n",
    "y_train = y_train_dm\n",
    "\n",
    "X_test = X_test_dm\n",
    "y_test = y_test_dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[CV] C=1, gamma=1, kernel=linear .....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................... C=1, gamma=1, kernel=linear, total=   2.9s\n",
      "[CV] C=1, gamma=1, kernel=linear .....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................... C=1, gamma=1, kernel=linear, total=   3.2s\n",
      "[CV] C=1, gamma=1, kernel=linear .....................................\n",
      "[CV] ...................... C=1, gamma=1, kernel=linear, total=   3.1s\n",
      "[CV] C=10, gamma=1, kernel=linear ....................................\n",
      "[CV] ..................... C=10, gamma=1, kernel=linear, total=   3.0s\n",
      "[CV] C=10, gamma=1, kernel=linear ....................................\n",
      "[CV] ..................... C=10, gamma=1, kernel=linear, total=   3.1s\n",
      "[CV] C=10, gamma=1, kernel=linear ....................................\n",
      "[CV] ..................... C=10, gamma=1, kernel=linear, total=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   23.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training process...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "import pickle\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import linear_model, datasets\n",
    "\n",
    "# Choose some parameter combinations to try\n",
    "param_grid = {'C':[1,10],'gamma':[1], 'kernel':['linear']}\n",
    "clf = SVC(decision_function_shape = \"ovr\")\n",
    "\n",
    "# Run the grid search\n",
    "grid_obj = GridSearchCV(clf,param_grid,refit = True, verbose=2)\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Set the clf to the best combination of parameters\n",
    "clf = grid_obj.best_estimator_\n",
    "\n",
    "#this is the classifier used for feature selection\n",
    "clf_pipe_multiclass = Pipeline([('model', clf)])\n",
    "\n",
    "# Fit the best algorithm to the data\n",
    "print (\"Start training process...\")\n",
    "clf_multiclass = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.49454545454545457\n",
      "Precision: 0.5597724760676217\n",
      "Recall: 0.49454545454545457\n",
      "F1 score: 0.4686567290965292\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.80      0.49       137\n",
      "          10       1.00      0.09      0.17        11\n",
      "         11a       0.75      0.25      0.38        12\n",
      "         11b       0.00      0.00      0.00         3\n",
      "         12a       0.65      0.55      0.60        56\n",
      "         12b       1.00      0.06      0.11        17\n",
      "          3a       0.62      0.53      0.57        15\n",
      "          3b       0.00      0.00      0.00         3\n",
      "          4a       0.73      0.51      0.60        37\n",
      "          4b       0.00      0.00      0.00        10\n",
      "           5       0.48      0.23      0.31        52\n",
      "          6a       0.68      0.53      0.60       132\n",
      "          6b       0.00      0.00      0.00         3\n",
      "          7a       1.00      0.47      0.64        30\n",
      "          7b       0.00      0.00      0.00         6\n",
      "          8a       0.00      0.00      0.00        10\n",
      "          8b       0.50      0.30      0.37        10\n",
      "           9       0.00      0.00      0.00         6\n",
      "\n",
      "   micro avg       0.49      0.49      0.49       550\n",
      "   macro avg       0.43      0.24      0.27       550\n",
      "weighted avg       0.56      0.49      0.47       550\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# save the models to disk\n",
    "filename_classifier = '/efs/lhoang2/Models/model_BOW_ManualDataOnly_NewSplit.sav'\n",
    "pickle.dump(clf_multiclass, open(filename_classifier, 'wb'))\n",
    "\n",
    "#Test SET\n",
    "#Run the model on Test set\n",
    "X_test = X_test_dm\n",
    "y_test = y_test_dm\n",
    "# Get validation results\n",
    "predictions_multiclass = clf_multiclass.predict(X_test)\n",
    "#Print Accurancy, ROC AUC, F1 Scores, Recall, Precision)\n",
    "print ('Accuracy:', accuracy_score(y_test, predictions_multiclass))\n",
    "print ('Precision:', precision_score(y_test, predictions_multiclass,average='weighted'))\n",
    "print ('Recall:', recall_score(y_test, predictions_multiclass,average='weighted'))\n",
    "print ('F1 score:', f1_score(y_test, predictions_multiclass,average='weighted'))\n",
    "print (classification_report(y_test,predictions_multiclass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
